---
title: "Models Business Analytics"
output: html_notebook
Author: Brocco Mattia, Cabrele Sofia, Piccolo Giulio
Date: 25/10/2020
---

```{r, message = FALSE, echo = FALSE}
library(DMwR)
library(plyr)
library(ROCR)
library(caret)
library(dplyr)
library(mosaic)
library(ggplot2)
library(lattice)
library(viridis)
library(reshape2)
library(imbalance)
library(tidyverse)
```


# 1. Load the file and fix the import
```{r message = FALSE, warning = FALSE}
df <- read_csv("C:/Users/matti/Desktop/BA Year 3/1. Business analytics/4. Project/customer_data.csv")
df <- as.data.frame(df)
df <- subset(df, select = -c(X1, codcliente, abb13, ultimo_ing.x) )

names(df)[16] <- "CARTA.DI.CREDITO"
names(df)[18] <- "NESSUN.PAGAMENTO"
names(df)[21] <- "CRAL.ORO.ASSOCIAZ"
names(df)[22] <- "MUS.TEATR.EDICOL" 
names(df)[23] <- "OFFERTE.GRUPPI"
names(df)[24] <- "PUNTO.INFORMATIVO.COMMERCIALE.NAN"

df$compagnia <- as.factor(df$compagnia)
df$Arte <- as.factor(df$Arte)
df$Non.appassionato <- as.factor(df$Non.appassionato)
df$Parco <- as.factor(df$Parco)
df$Scienze <- as.factor(df$Scienze)
df$Sport <- as.factor(df$Sport)
df$Storia <- as.factor(df$Storia)
df$nuovo_abb <- as.factor(df$nuovo_abb)
df$femmina <- as.factor(df$femmina)
df$BANCOMAT <- as.factor(df$BANCOMAT)
df$CARTA.DI.CREDITO <- as.factor(df$CARTA.DI.CREDITO)
df$CONTANTI <- as.factor(df$CONTANTI)
df$NESSUN.PAGAMENTO <- as.factor(df$NESSUN.PAGAMENTO)
df$PI <- as.factor(df$PI)
df$TO <- as.factor(df$TO)
df$CRAL.ORO.ASSOCIAZ <- as.factor(df$CRAL.ORO.ASSOCIAZ)
df$MUS.TEATR.EDICOL <- as.factor(df$MUS.TEATR.EDICOL)
df$OFFERTE.GRUPPI <- as.factor(df$OFFERTE.GRUPPI)
df$PUNTO.INFORMATIVO.COMMERCIALE.NAN <- as.factor(df$PUNTO.INFORMATIVO.COMMERCIALE.NAN)
df$si2014 <- as.factor(df$si2014)
```



```{r}
# Remove the outliers in frequenza, variety ed age.
# First, those in "age" because there were values < 0 and < 105.
# Then, "frequenza" (values > 100) that consequently fixed "variety" too.

df <- subset(df, df$age > 0)
df <- subset(df, df$age < 105)
df <- subset(df, df$frequenza < 100)

head(df)
dim(df)
```

```{r}
# Further exploratory description of numeric variables
favstats(df$frequenza)
densityplot(df$frequenza, col = "#8196D2", lwd = 2)

favstats(df$importo_tot)
densityplot(df$importo_tot, col = "#8196D2", lwd = 2)

favstats(df$age)
densityplot(df$age, col = "#8196D2", lwd = 2)

# Age density plot broken down by sex
densityplot(~as.numeric(age), data = df, groups = femmina,
            plot.point = FALSE, lwd = 3, na.rm = TRUE,
            main = "Age density plot broken down by sex", auto.key = TRUE)

# Age density plot broken down by entrances in groups
densityplot(~as.numeric(age), data = df, groups = compagnia,
            na.rm = TRUE, main = "Age density plot broken down by entrances in groups",
            auto.key = T, plot.point = FALSE, lwd = 3,
            par.settings = list(superpose.line = list(col = c("#4B2991","#D44292") )) )

# Age density plot broken down by renewal
densityplot(~as.numeric(age), data = df, groups = si2014, plot.point = FALSE, lwd = 3,
            na.rm = TRUE, main = "Age density plot broken down by renewal", auto.key = T,
            par.settings = list(superpose.line = list(col = c("#4B2991","#D44292") )) )
```





# 2. Correlation assessment
```{r, message = FALSE}
# Assessment of the correlation between features

num.var.df<- select(df, "frequenza", "importo_tot", "variety", "prezzo_card", "age", "day_y_purchase", "span.utilizzo")

to.corr <- round(cor(num.var.df),3)

melted_corr <- melt(to.corr)
ggplot(data = melted_corr, aes(x = Var1, y = Var2, fill = value)) + geom_tile() + scale_fill_viridis_c(option = "magma") + labs(title = "Dataframe's Correlation Matrix", subtitle = "Only numeric variables included", fill = "Pearson's\nCorrelation") +
scale_x_discrete(expand = c(0,0)) + scale_y_discrete(expand = c(0,0))
```


# 3. SMOTE, Variable selection & Train-Test Split
This part is required in order to overcome two problems: on the one hand, unbalanced target class with SMOTE technique, on the other hand, feature selection to improve future models through a logistic regression.

```{r}
# Solve the problem of unbalanced sampling problem with SMOTE (by setting perc.over = 100% we avoid creating new instances, but with perc.under = 150% we are reducing the number of instances with the majority class, that is 1).

t1 <- Sys.time()
newdf <- SMOTE(form = si2014~., data = df, perc.over = 100, perc.under = 150)
newdf <- as.data.frame(newdf)

t2 <- Sys.time()
t2-t1
dim(newdf)

ggplot(newdf, aes(x = si2014)) + geom_bar(aes(y = (..count..)/sum(..count..)), fill = "#8196D2") + scale_y_continuous(labels = scales::percent) + theme_classic()
```

```{r}
# LOGIT TO SELECT THE MOST RELEVANT VARIABLES IN THE DF
logit.x.var <- glm(si2014 ~ ., data = newdf, family = binomial(link = "logit"))
summary(logit.x.var)
```

The features that will be dropped, due to low significance (at a threshold of $p-value <= 0.01$), are:

* Non.appassionato
* Parco
* Scienze
* nuovo_abb
* femmina
* Carta di credito
* Contanti
* Nessun Pagamento
* Musei/teatri/edicole
* Punto informativo/commerciale/nan values

```{r}
newdf <- subset(newdf, select = -c(Non.appassionato, Parco, Scienze, nuovo_abb, femmina, CARTA.DI.CREDITO, CONTANTI, NESSUN.PAGAMENTO, MUS.TEATR.EDICOL, PUNTO.INFORMATIVO.COMMERCIALE.NAN))
```

```{r}
# Train and test split (70% train)
set.seed(101)
split.df <- sample(seq_len(nrow(newdf)), size = 0.7*nrow(newdf))
train.df <- newdf[split.df, ]
test.df <- newdf[- split.df, ]

dim(train.df)
dim(test.df)
```

# MODEL DEPLOYMENT
To tackle the churn problem, we've deployed, tuned and compared four models, that are:

1. Logit
  + To use its performance as a benchmark with the other models, considering that `logit` is the basic classifier
  + To have a glimpse on the most important variable for this model
2. Boosted Logistic regression
3. Boosted Tree
4. Flexible Discriminant Analysis
5. Bagged Tree

## MODEL 1. Logistic regression

```{r}
glm.model <- glm(si2014 ~ ., data = train.df, family = binomial(link = "logit"))
glm.prob <- predict(glm.model, newdata = test.df, type = "response")

summary(glm.model)
```


```{r}
#COMPUTE SCORES OF THE LOGIT (accuracy, ...)
glm.pred <- ifelse(glm.prob > 0.5, 1, 0)
scores <- table(test.df$si2014, glm.pred)
scores
```


```{r}
# According to the following models, whose metrics are compute by "caret", here TP are (0,0) and TN are (1,1)
cat("Accuracy:",(scores[2,2]+scores[1,1])/sum(scores),"\n")
cat("Precision:", scores[1,1]/(scores[1,1]+scores[2,1]),"\n")
cat("Sensitivity:", scores[1,1]/(scores[1,1]+scores[1,2]),"\n")
cat("Specificity:", scores[2,2]/(scores[2,2]+scores[2,1]),"\n")
cat("1-Specificity:", scores[2,1]/(scores[2,1]+scores[2,2]))

#cat("Accuracy:",(scores[2,2]+scores[1,1])/sum(scores),"\n")
#cat("Sensitivity:", scores[2,2]/(scores[2,2]+scores[1,2]),"\n")
#cat("Precision:", scores[2,2]/(scores[2,2]+scores[2,1]),"\n")
#cat("Specificity:", scores[1,1]/(scores[1,1]+scores[2,1]),"\n")
#cat("1-Specificity:", scores[2,1]/(scores[2,1]+scores[1,1]))
```

## MODEL 2. Boosted Logistic regression
We've added this model to see whether the logit (that is a weak learner), when combined with `boosting`, increased its performance. Boosting implies that a weak learner learns in an adaptive and sequential way. In this model we've iterated this process (`nIter`) $20$ times. Furthermore, the model is validated with `3-fold Cross Validation`; 3 is chosen as a trade-off between time and effectiveness.

```{r}
library(caTools)

logreg_tune <- data.frame(nIter = seq(1,20, by = 1))
t1 <- Sys.time()
logreg_mod <- train(si2014 ~., data = train.df, method = "LogitBoost", tuneGrid = logreg_tune,
                trControl = trainControl(method = "cv", number = 3, allowParallel = TRUE))
t2 <- Sys.time()
t2-t1
logreg_mod
```

Then, for every iteration the accuracy is plotted below. We can see how there is a slight trend toward the upper-right corner, nonetheless the accuracy metric is highly fluctuating.

```{r}
ggplot(logreg_mod) +
  geom_line(color = "#8196D2") + geom_point(color = "#8196D2") + theme_classic() 
```


```{r}
logreg.pred <- predict(logreg_mod, test.df)
logreg.prob <- predict(logreg_mod, newdata = test.df, type = "prob")
confusionMatrix(data = logreg.pred, reference = test.df$si2014)
```
With this model we've achieved a $93%$ accuracy, with more-than-encouraging results both for Sensitivity ($95%$) and Specificity ($88%$).

## MODEL 3. Boosted Classification Tree
Again, we wanted to pursue better results by combining learners with ensemble methods. For what concerns the hyperparameters' tuning, we considered the number of Boosting iterations (`iter`, that by default is 50), the maximum depth of the tree (`maxdepth`) and the shrinkage parameter for boosting (`nu`, default value is 1)

```{r, message = FALSE}
library(ada)

bctree_tune <- data.frame(iter = seq(10, 100, by = 10),
                          maxdepth = seq(1, 10, by = 1),
                          nu = seq(0.1, 1, by = 0.1) )

t1 <- Sys.time()
bctree_mod <- train(si2014 ~., data = train.df, method = "ada", tuneGrid = bctree_tune,
                trControl = trainControl(method = "cv", number = 3, allowParallel = TRUE))
t2 <- Sys.time()
t2-t1

bctree_mod
```

Then, for each iteration of the `Grid Search with 3-fold CV`, as tree max depth, $nu$ and number of trees changed, the accuracy is shown in the following graph.
```{r}
plot(bctree_mod)
```


```{r}
bctree.pred <- predict(bctree_mod, test.df)
bctree.prob <- predict(bctree_mod, newdata = test.df, type = "prob")
confusionMatrix(data = bctree.pred, reference = test.df$si2014)
```
With this model we've achieved a $81%$ accuracy, with encouraging results both for Sensitivity ($82%$) and Specificity ($80%$). Overall, the BCT showed slightly poorer performance than the previous model.

## MODEL 4. Flexible Discriminant Analysis

The FDA is a complex model for classification that exploits several learners (linear regressions), that uses optimization algorithms to improve _linear separation_, and finally _MARS_ (Multivariate Adaptive Regression Splines) to generate the best hyperplane.

The model's hyperparamters that have been tuned are

* `degree`: refers to $Friedman's mi$, which by default is 1.
* `nprune`: the maximum number of terms, including the intercept. By default it's `NULL`, but to reduce computational effort we've set an lower bound to 7 ( $=10-(ncol(train.df)-1)$ ), and the upper comes from the `train.df` dimension

```{r, message = FALSE, warning = FALSE}
library(mda)
library(earth)

fda_tune <- data.frame(degree = seq(1,10, by = 1),
                       nprune = seq(7,16, by = 1))

t1 <- Sys.time()
fda_mod <- train(si2014 ~., data = train.df, method = "fda", tuneGrid = fda_tune,
                 trControl = trainControl(method = "cv", number = 3, allowParallel = TRUE))
t2 <- Sys.time()

t2-t1

fda_mod
```


Then, for each iteration of the `Grid Search with 3-fold CV`, as the degree and nprune changed, the accuracy is shown in the following graph.
```{r}
plot(fda_mod)
```


```{r}
fda.pred <- predict(fda_mod, test.df)
fda.prob <- predict(fda_mod, newdata = test.df, type = "prob")
confusionMatrix(data = fda.pred, reference = test.df$si2014)
```
With this model we've achieved an $77%$ accuracy, and also Sensitivity ($81%$) and Specificity ($~72%$) outline a fair performance. Overall, the FDA did not performed better than the previous models in any of the relevant metrics.


## MODEL 5. Bootstrap Aggregating Recursive Partitioning Tree
As our fifth and last model, we wanted to try with another ensemble method, that is Bagging. In this case, we did not perform any model tuning in order to see how well a bagged tree alone could perform against the previous tree model.
```{r}
library(ipred)

t1 <- Sys.time()
bag_mod <- bagging(si2014 ~ ., data = train.df)

t2 <- Sys.time()
t2-t1

bag_mod
```


```{r}
bag.pred <- predict(bag_mod, test.df)
bag.prob <- predict(bag_mod, newdata = test.df, type = "prob")
confusionMatrix(data = bag.pred, reference = test.df$si2014)
```
With this model we've achieved an $83%$ accuracy, and also Sensitivity ($~84%$) and Specificity ($82%$) outline a pretty good performance. In the end, the `Bagged Tree` outperformed the `BCT` for both Sensitivity ($+2%$) and Specificity ($+2%$), even if this model was not subject to tuning.


# MODEL EVALUATION

## ROC curves
```{r}
#0) create an ROCR prediction object from glm() probabilities
x.glm.prob.rocr <- prediction(glm.prob, test.df['si2014'])
# prepare an ROCR performance object for ROC curve 
#(tpr=true positive rate, fpr=false positive rate)
x.glm.perf <- performance(x.glm.prob.rocr, "tpr","fpr")
plot(x.glm.perf, col = "#F3B584", main = "ROC curves for 5 models", lwd = 3)
# ---------------------------------------------------------------------
logreg_mod.prob.rocr <- prediction(logreg.prob[,2], test.df['si2014'])
logreg_mod.perf <- performance(logreg_mod.prob.rocr, "tpr","fpr")
plot(logreg_mod.perf, col = "#F66D7A", add = TRUE, lwd = 3)
# ---------------------------------------------------------------------
bctree_mod.prob.rocr <- prediction(bctree.prob[,2], test.df['si2014'])
bctree_mod.perf <- performance(bctree_mod.prob.rocr, "tpr","fpr")
plot(bctree_mod.perf, col = "#D44292", add = TRUE, lwd = 3)
# ---------------------------------------------------------------------
fda_mod.prob.rocr <- prediction(fda.prob[,2], test.df['si2014'])
fda_mod.perf <- performance(fda_mod.prob.rocr, "tpr","fpr")
plot(fda_mod.perf, col = "#952EA0", add = TRUE, lwd = 3)
# ---------------------------------------------------------------------
bag_mod.prob.rocr <- prediction(bag.prob[,2], test.df['si2014'])
bag_mod.perf <- performance(bag_mod.prob.rocr, "tpr","fpr")
plot(bag_mod.perf, col = "#4B2991", add = TRUE, lwd = 3)

legend("bottomright", legend = c("Logit", "Boosted Logit", "Boosted Tree", "FDA", "Tree Bagging"),
       col = c("#F3B584", "#F66D7A", "#D44292", "#952EA0","#4B2991"), cex = .8, lty = 1:1)

lines(c(0,1), c(0,1), lwd = 2, lty = "dashed")
```


## LIFT curves
```{r}
lift1 <- performance(x.glm.prob.rocr,"lift", "rpp") #rate of positive prediction
plot(lift1, main = "LIFT curves for 5 models", lwd = 2.5, col = "#F3B584", ylim = c(-0.1,2.6))
# ------------------------------------------------------
lift2 <- performance(logreg_mod.prob.rocr,"lift", "rpp")
plot(lift2, add = TRUE, lwd = 2.5, col = "#F66D7A")
# ------------------------------------------------------
lift3 <- performance(bctree_mod.prob.rocr,"lift", "rpp")
plot(lift3, add = TRUE, lwd = 2.5, col = "#D44292")
# ------------------------------------------------------
lift4 <- performance(fda_mod.prob.rocr,"lift", "rpp")
plot(lift4, add = TRUE, lwd = 2.5, col = "#952EA0")
# ------------------------------------------------------
lift5 <- performance(bag_mod.prob.rocr,"lift", "rpp")
plot(lift5, add = TRUE, lwd = 2.5, col = "#4B2991")

abline(h = 1)

legend("bottomright", legend = c("Logit", "Boosted Logit", "Boosted Tree", "FDA", "Tree Bagging"),
       col = c("#F3B584", "#F66D7A", "#D44292", "#952EA0","#4B2991"), cex = .8, lty = 1:1)
```

## GAIN curves
A vertical line at a value corresponding to $0.24$ a vertical line, that stands for the number of customer we will contact over the total number of instances we had in the test set. At this value we can already see a difference between the models that we've taken into consideration.
```{r}
gain1 <- performance(x.glm.prob.rocr,"tpr","rpp")
plot(gain1, col = "#F3B584", main="GAIN CHART for 5 models", lwd = 3)
# ------------------------------------------------------
gain2 <- performance(logreg_mod.prob.rocr,"tpr","rpp")
plot(gain2, col = "#F66D7A", add = TRUE, lwd = 3)
# ------------------------------------------------------
gain3 <- performance(bctree_mod.prob.rocr,"tpr","rpp")
plot(gain3, col = "#D44292", add = TRUE, lwd = 3)
# ------------------------------------------------------
gain4 <- performance(fda_mod.prob.rocr,"tpr","rpp")
plot(gain4, col = "#952EA0", add = TRUE, lwd = 3)
# ------------------------------------------------------
gain5 <- performance(bag_mod.prob.rocr,"tpr","rpp")
plot(gain5, col = "#4B2991", add = TRUE, lwd = 3)

legend("bottomright", legend = c("Logit", "Boosted Logit", "Boosted Tree", "FDA", "Tree Bagging"),
       col = c("#F3B584", "#F66D7A", "#D44292", "#952EA0","#4B2991"), cex = .8, lty = 1:1)

abline(v = 5000/nrow(test.df), par(lty = "dashed"))
```

## PROFIT curves

Profit is defined as $Profit = Revenues-Costs$, where $Revenues = Card Price$ and $Costs = 1 + (1/2)*import_tot$. Indeed, revenues coincide with the price paid by customers, while costs with the administrative cost of the phone call, plus half of the amount of money each customer has spent for visiting museums (by definition of this business model).
This implies that an increase in the total amount spent by a customer, results in a massive decrease in the profit from that customer.

```{r}
#1)Logit
newdata1 <- test.df
newdata1$glm.prob <- glm.prob
newdata1$profit <- (newdata1$glm.prob*newdata1$prezzo_card) - (1+(newdata1$importo_tot*(0.5))) 
newdata1 <- newdata1[order(-newdata1$glm.prob),]
newdata1$cumprof <- cumsum(newdata1$profit)
plot(newdata1$cumprof, col = "#F3B584", xlab = "nr instances", lwd = 3, ylim = c(-3e5,1.5e5),
     ylab = "Cumulative profit", main = "PROFIT CURVES for 5 models")
#2)Boosted Logit
newdata2 <- test.df
newdata2$logreg.prob <- logreg.prob[,2]
newdata2$profit <- (newdata2$logreg.prob*newdata2$prezzo_card) - (1+(newdata2$importo_tot*(0.5))) 
newdata2 <- newdata2[order(-newdata2$logreg.prob),]
newdata2$cumprof <- cumsum(newdata2$profit)
lines(newdata2$cumprof, col = "#F66D7A", lwd = 3)
#3)Boosted Tree
newdata3 <- test.df
newdata3$bctree.prob <- bctree.prob[,2]
newdata3$profit <- (newdata3$bctree.prob*newdata3$prezzo_card) - (1+(newdata3$importo_tot*(0.5))) 
newdata3 <- newdata3[order(-newdata3$bctree.prob),]
newdata3$cumprof <- cumsum(newdata3$profit)
lines(newdata3$cumprof, col = "#D44292", lwd = 3)
#4)FDA
newdata4 <- test.df
newdata4$fda.prob <- fda.prob[,2]
newdata4$profit <- (newdata4$fda.prob*newdata4$prezzo_card) - (1+(newdata4$importo_tot*(0.5))) 
newdata4 <- newdata4[order(-newdata4$fda.prob),]
newdata4$cumprof <- cumsum(newdata4$profit)
lines(newdata4$cumprof, col = "#952EA0", lwd = 3)
#5) Bagged Tree
newdata5 <- test.df
newdata5$bagg.prob <- bag.prob[,2]
newdata5$profit <- (newdata5$bagg.prob*newdata5$prezzo_card) - (1+(newdata5$importo_tot*(0.5))) 
newdata5 <- newdata5[order(-newdata5$bagg.prob),]
newdata5$cumprof <- cumsum(newdata5$profit)
lines(newdata5$cumprof, col = "#4B2991", lwd = 3)

#abline(v = 5000, par(lty = "dashed"))

legend("bottomleft", legend = c("Logit", "Boosted Logit", "Boosted Tree", "FDA", "Tree Bagging"),
       col = c("#F3B584", "#F66D7A", "#D44292", "#952EA0","#4B2991"), cex = .8, lty = 1:1)

abline(a = 0, b = (-3e+05/20000), lty = "dashed", lwd = 2)
```

The most profitable model is _Boosted Tree_. Which is a revolution for us, since according to mere performance the best model was the _Bagging RTree_, nonetheless what really matters to the business is the financial side.

# THE 5000 HEADS TO CALL
```{r}
# SELECTING ONLY THE LAST 5000 ROWS OF THE DATAFRAME CONTAINING ONLY POSITIVE PROFITS, ORDERED BY SCORE.
# THIS WAY WE CAN TARGET ONLY THOSE THAT ARE PROFITABLE, WHILE AT THE SAME TIME REDUCING THE WASTE OF CONTACTING CUSTOMERS THAT WILL (ALMOST) SURELY RENEW

top5000 <- subset(newdata3, newdata3$profit > 0)[4287:9286,]
top5000
```


```{r}
ggplot(top5000, aes(x = si2014)) + geom_bar(fill = "#8196D2") + theme_classic()
```

```{r}
densityplot(top5000$profit, col = "#8196D2", lwd = 3)
```

```{r}
favstats(top5000$profit)
```



